spring.application.name=avro

# Confluent Cloud Schema Registry
spring.kafka.properties.basic.auth.credentials.source=USER_INFO
spring.kafka.properties.basic.auth.user.info=<SCHEMA_REGISTRY_API_KEY>:<SCHEMA_SCHEMA_REGISTRY_SECRET>
spring.kafka.properties.schema.registry.url=<SCHEMA_URL>

# Required connection configs for Kafka producer, consumer, and admin
spring.kafka.properties.sasl.mechanism=PLAIN
spring.kafka.bootstrap-servers=<BROKER_URL>
spring.kafka.properties.sasl.jaas.config=org.apache.kafka.common.security.plain.PlainLoginModule required username='KAFKA_API_KEY' password='KAFKA_SECRET';
spring.kafka.properties.security.protocol=SASL_SSL

# Best practice for higher availability in Apache Kafka clients prior to 3.0
spring.kafka.properties.session.timeout.ms=45000

spring.kafka.producer.key-serializer=org.apache.kafka.common.serialization.StringSerializer
spring.kafka.producer.value-serializer=io.confluent.kafka.serializers.json.KafkaJsonSchemaSerializer

spring.kafka.consumer.key-deserializer=org.apache.kafka.common.serialization.StringDeserializer
spring.kafka.consumer.value-deserializer=io.confluent.kafka.serializers.json.KafkaJsonSchemaDeserializer
spring.kafka.properties.auto.register.schemas=false
spring.kafka.properties.use.latest.version=true

auto.register.schemas=false
spring.devtools.enabled=true
server.port=8081

socket.host=0.0.0.0
socket.port=3001

debug.enabled=true
topic.name=<TOPIC_NAME>


# These properties are required for encryption/decryption if you're using not sharing the key to the confluent.
# rule.executors=aws
# rule.executors.aws.class=io.confluent.kafka.schemaregistry.encryption.aws.AwsFieldEncryptionExecutor
# rule.executors._default_.param.access.key.id=ACCESS_KEY_ID
# rule.executors._default_.param.secret.access.key=SECRET_ACCESS_KEY
