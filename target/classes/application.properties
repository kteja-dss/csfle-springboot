spring.application.name=avro

# Confluent Cloud Schema Registry
spring.kafka.properties.basic.auth.credentials.source=USER_INFO
spring.kafka.properties.basic.auth.user.info=IXBINGUFYHXOHSPR:RA2brSmhnU7XsKE1cso8H18xPLjAl3FDwcNlfCXlhJX8Yz7K/rwceV5bshDAuEXQ
spring.kafka.properties.schema.registry.url=https://psrc-l622j.us-east-2.aws.confluent.cloud

# Required connection configs for Kafka producer, consumer, and admin
spring.kafka.properties.sasl.mechanism=PLAIN
spring.kafka.bootstrap-servers=pkc-l7pr2.ap-south-1.aws.confluent.cloud:9092
spring.kafka.properties.sasl.jaas.config=org.apache.kafka.common.security.plain.PlainLoginModule required username='CRWFDZ6XGVYYU5ZM' password='/tP9u974/f4P7Bms7VtnDtYmgspsET9as5Te6CgBStO8JZeOaqdZFcGoqP2Rq3xa';
spring.kafka.properties.security.protocol=SASL_SSL

# Best practice for higher availability in Apache Kafka clients prior to 3.0
spring.kafka.properties.session.timeout.ms=45000

spring.kafka.producer.key-serializer=org.apache.kafka.common.serialization.StringSerializer
spring.kafka.producer.value-serializer=io.confluent.kafka.serializers.json.KafkaJsonSchemaSerializer

spring.kafka.consumer.key-deserializer=org.apache.kafka.common.serialization.StringDeserializer
spring.kafka.consumer.value-deserializer=io.confluent.kafka.serializers.json.KafkaJsonSchemaDeserializer
spring.kafka.properties.auto.register.schemas=false
spring.kafka.properties.use.latest.version=true

auto.register.schemas=false
spring.devtools.enabled=true
server.port=8081

socket.host=0.0.0.0
socket.port=3001

debug.enabled=true
topic.name=employee_data_json


# These properties are required for encryption/decryption if you're using not sharing the key to the confluent.
# rule.executors=aws
# rule.executors.aws.class=io.confluent.kafka.schemaregistry.encryption.aws.AwsFieldEncryptionExecutor
# rule.executors._default_.param.access.key.id=ACCESS_KEY_ID
# rule.executors._default_.param.secret.access.key=SECRET_ACCESS_KEY